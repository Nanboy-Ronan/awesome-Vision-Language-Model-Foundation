# Awesome Vision Language Model and Foundation Models

[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation/graphs/commit-activity)
![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)
![ ](https://img.shields.io/github/last-commit/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation)
[![GitHub stars](https://img.shields.io/github/stars/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation?color=blue&style=plastic)](https://github.com/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation/stargazers)
[![GitHub watchers](https://img.shields.io/github/watchers/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation?color=yellow&style=plastic)](https://github.com/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation)
[![GitHub forks](https://img.shields.io/github/forks/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation?color=red&style=plastic)](https://github.com/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation/watchers)
[![GitHub Contributors](https://img.shields.io/github/contributors/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation?color=green&style=plastic)](https://github.com/Nanboy-Ronan/awesome-Vision-Language-Model-Foundation/network/members)


## Table of Contents

## Survey
<details>
<summary>Survey: 2024</summary>

- Medical Vision Language Pretraining: A Survey. [[paper]](https://arxiv.org/abs/2312.06224)
  - Patrick Mineault, Niccol√≤ Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias.
  - Key Words: Medical AI; Vision-Language Models; Pretraining; Multimodal Learning; Representation Learning.
  - <details><summary>Digest</summary> 
    This survey provides a comprehensive overview of medical vision-language pretraining (MedVLP), an emerging field in AI that integrates vision and language understanding for medical applications. The authors examine various MedVLP architectures, training objectives, and datasets, highlighting their effectiveness in downstream clinical and biomedical tasks. The paper discusses challenges such as data scarcity, bias, and model interpretability while proposing future research directions, including better multimodal fusion strategies, improved benchmark datasets, and robust evaluation frameworks.
  </details>
</details>

## CLIP and Its Variant

## Text2Image Models

## Language Modeling

### Vision Language Models

### Vision Large Language Models
